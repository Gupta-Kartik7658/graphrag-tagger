{
  "chunk": "[101] train a PLM to\nAnother category utilizes the similarity between queries and retrieved information for ranking.\nFor instance, Cheng et al. [20] re-rank the candidate subgraphs based on the similarity for both relation and fine-grained concept between subgraphs and the query. Taunk et al. [158] first cluster the 2-hop neighbors and then delete the cluster with the lowest similarity score with the input query. Yasunaga et al. [189] prune the retrieved subgraph according to the relevance score between the question context and the KG entity nodes calculated by a pre-trained language model.\nWang et al. [171] , Jiang et al. [70] , Guti√©rrez et al. [51] and Luo et al. [110] adopt Personalized PageRank algorithm to rank the retrieved candidate information for further filtering. Liu et al. [101] trains\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: September 2024.",
  "source_file": "Sample PDf\\Graph Retrieval-Augmented Generation.pdf",
  "classification": {
    "content_type": "paragraph",
    "is_sufficient": true,
    "topics": [
      "Retrieval Methods",
      "Knowledge Graphs",
      "Training Techniques"
    ]
  }
}