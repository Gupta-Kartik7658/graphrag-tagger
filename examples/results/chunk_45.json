{
  "chunk": "tonomously determine the optimal moments to finish the retrieval activities. For instance, [50, 182] leverage an LM for hop prediction, which serves as an indicator to end the retrieval. There is also a group of researchers who utilize model-generated special tokens or texts as termination signals for the retrieval process. For example, ToG [113, 154] prompts the LLM agent to explore the multiple possible reasoning paths until the LLM determines the question can be answered based on the current reasoning path. [196] trains a RoBERTa to expand a path from each topic entity. In the process, a virtual relation named as “[END]” is introduced to terminate the retrieval process.\nAnother common approach involves treating the large model as an agent, enabling it to directly generate answers to questions to signal the end of iteration. For instance, [67, 69, 75, 155, 170] propose LLM-based agents to reason on graphs. These agents could autonomously determine the information for retrieval, invoke the pre-defined retrieval tools, and cease the retrieval process based on the retrieved information.\n6.2.3",
  "source_file": "Sample PDf\\Graph Retrieval-Augmented Generation.pdf",
  "classification": {
    "content_type": "paragraph",
    "is_sufficient": true,
    "topics": [
      "Topic 3",
      "Topic 11",
      "Topic 8"
    ]
  }
}