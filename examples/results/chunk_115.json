{
  "chunk": "with Memory Networks. arXiv:1506.02075 [cs.LG] https://arxiv.org/abs/1506.02075 [14] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan,\nPranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems 33 (2020), 1877–1901.\n[15] Andrew Carlson, Justin Betteridge, Bryan Kisiel, Burr Settles, Estevam R. Hruschka Jr., and Tom M. Mitchell. 2010.\nToward an Architecture for Never-Ending Language Learning. In Proceedings of the Twenty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2010, Atlanta, Georgia, USA, July 11-15, 2010. 1306–1313.\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: September 2024.",
  "source_file": "Sample PDf\\Graph Retrieval-Augmented Generation.pdf",
  "classification": {
    "content_type": "citation",
    "is_sufficient": true,
    "topics": [
      "Natural Language Processing",
      "Training Techniques"
    ]
  }
}