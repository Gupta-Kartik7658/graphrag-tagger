{
  "chunk": "marks specifically designed for the GraphRAG systems. These benchmarks usually cover multiple task domains to provide a comprehensive test result. For example, STARK [179] benchmarks\nLLM Retrieval on semi-structured knowledge bases covering three domains, including product search, academic paper search, and queries in precision medicine to access the capacity of current\nGraphRAG systems. He et al. [55] propose a flexible question-answering benchmark targeting real-world textual graphs, named GraphQA, which is applicable to multiple applications including scene graph understanding, commonsense reasoning, and knowledge graph reasoning. Graph\nReasoning Benchmark (GRBENCH) [75] is constructed to facilitate the research of augmenting\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: September 2024.",
  "source_file": "Sample PDf\\Graph Retrieval-Augmented Generation.pdf",
  "classification": {
    "content_type": "paragraph",
    "is_sufficient": true,
    "topics": [
      "Topic 3",
      "Topic 4",
      "Topic 10"
    ]
  }
}