import ktrain
from ktrain.text import get_topic_model


class TopicExtractor:
    def __init__(
        self,
        n_features: int = 512,
        min_df: int = 2,
        max_df: float = 0.95,
        threshold: float = 0.25,
    ):
        """
        Initialize the TopicExtractor with ktrain parameters.
        """
        self.n_features = n_features
        self.min_df = min_df
        self.max_df = max_df
        self.threshold = threshold
        self.tm = None

    def fit(self, texts: list[str]):
        """
        Build the topic model using the provided texts.
        """
        self.tm = get_topic_model(
            texts, n_features=self.n_features, min_df=self.min_df, max_df=self.max_df
        )
        self.tm.build(texts, threshold=self.threshold)
        return self

    def get_topics(self) -> list[str]:
        """
        Retrieve the topics generated by the LDA model.
        """
        if self.tm is None:
            raise ValueError("Topic model not built. Call fit() first.")
        topics = self.tm.get_topics()
        return topics

    def filter_texts(self, texts: list[str]) -> list[str]:
        """
        Optionally filter texts using the topic model.
        """
        if self.tm is None:
            raise ValueError("Topic model not built. Call fit() first.")
        return self.tm.filter(texts)
    
    def transform(self, texts: list[str], threshold = 0.25) -> list[list[float]]:
        """
        Transform texts into the topic space.
        """
        if self.tm is None:
            raise ValueError("Topic model not built. Call fit() first.")
        return self.tm.predict(texts, threshold=threshold)


# ----- Example usage -----
if __name__ == "__main__":
    from sklearn.datasets import fetch_20newsgroups

    # Sample texts â€“ in practice, these would be your document texts.
    remove = ("headers", "footers", "quotes")
    # newsgroups_train = fetch_20newsgroups(subset="train", remove=remove)
    newsgroups_test = fetch_20newsgroups(subset="test", remove=remove)
    texts: list[str] = newsgroups_test.data  # + newsgroups_train.data

    # Initialize and fit the topic extractor.
    extractor = TopicExtractor()
    extractor.fit(texts)

    # Retrieve the extracted (messy) topics.
    messy_topics = extractor.get_topics()
    print("Topics from LDA:")
    for topic in messy_topics:
        print("-", topic)

    # Optionally, transform new texts into the topic space.
    topic_distributions = extractor.transform(texts[-10:], 0)
    print("\nTopic distributions for sample texts:")
    print(topic_distributions)
